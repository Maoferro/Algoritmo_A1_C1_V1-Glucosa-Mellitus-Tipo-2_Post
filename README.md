# ü©∫ Predicci√≥n de Glucosa Postprandial con Machine Learning

## üìã Descripci√≥n General

Este proyecto desarrolla y compara **7 modelos de Machine Learning** diferentes para estimar y clasificar los niveles de **glucosa postprandial** (glucosa despu√©s de las comidas) bas√°ndose en caracter√≠sticas cl√≠nicas y antropom√©tricas del paciente. 

Todos los modelos siguen la misma metodolog√≠a y pipeline, variando solo el algoritmo de entrenamiento. Los modelos entrenados son:

1. Regresi√≥n Lineal
2. Ridge Regression
3. Lasso Regression
4. Random Forest
5. **Gradient Boosting** (usado como ejemplo en esta documentaci√≥n)
6. Support Vector Machine (SVM)
7. Red Neuronal (MLP)

El modelo es √∫til para evaluaciones de diabetes y prediabetes, clasificando autom√°ticamente los resultados en categor√≠as cl√≠nicas.

---

## üéØ Objetivo

- Estimar glucosa postprandial a partir de mediciones de glucosa en ayunas o general
- Clasificar autom√°ticamente los resultados en categor√≠as cl√≠nicas: **Normal**, **Prediabetes** o **Diabetes**
- Comparar desempe√±o entre 7 algoritmos diferentes
- Proporcionar predicciones precisas con m√©tricas de desempe√±o robustas
- Identificar el modelo √≥ptimo para m√°xima precisi√≥n

---

## üî¨ ¬øQu√© es Glucosa Postprandial?

La glucosa postprandial es la concentraci√≥n de glucosa en sangre medida **despu√©s de la ingesta de alimentos** (t√≠picamente 2 horas post-comida).

| Tipo de Medici√≥n | Momento | Rango Normal |
|-----------------|---------|-------------|
| **Glucosa en Ayunas** | Despu√©s de 8 horas sin comer | < 100 mg/dL |
| **Glucosa Postprandial** | 2 horas despu√©s de comer | < 140 mg/dL |
| **Glucosa Aleatoria** | Cualquier momento | < 140 mg/dL |

**Importancia cl√≠nica**:
- La glucosa postprandial es m√°s alta que en ayunas (~40 mg/dL m√°s)
- Es un predictor importante de diabetes
- Refleja la capacidad del p√°ncreas para regular insulina

---

## üì¶ Dependencias Requeridas

### Instalaci√≥n

```bash
pip install pandas numpy scikit-learn matplotlib seaborn joblib
```

### Versiones Recomendadas

```bash
pip install pandas>=1.3.0 numpy>=1.21.0 scikit-learn>=1.0.0 \
            matplotlib>=3.4.0 seaborn>=0.11.0 joblib>=1.0.0
```

---

## üîß Librer√≠as Utilizadas

### **Pandas**
```python
import pandas as pd
```

| Funci√≥n | Descripci√≥n |
|---------|-------------|
| `pd.read_csv()` | Carga archivo CSV desde Google Drive |
| `df.dropna()` | Elimina filas con valores faltantes |
| `df.apply()` | Aplica funci√≥n a cada fila para crear categor√≠as |

**Uso**: Manipulaci√≥n y limpieza de datos tabulares

---

### **NumPy**
```python
import numpy as np
```

- **Funci√≥n**: Operaciones num√©ricas subyacentes
- **Uso**: C√°lculos de m√©tricas (RMSE, MAE)
- **Por qu√©**: Base computacional eficiente para scikit-learn

---

### **Scikit-Learn**

#### `train_test_split`
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)
```

- **Funci√≥n**: Divide datos en 70% entrenamiento y 30% prueba
- **random_state=42**: Garantiza reproducibilidad
- **Ventaja**: Eval√∫a el modelo en datos nunca vistos

---

#### `OneHotEncoder`
```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(handle_unknown="ignore")
```

- **Funci√≥n**: Convierte variable categ√≥rica en num√©ricas binarias
- **Ejemplo**:
  ```
  Entrada:  ["Normal", "Prediabetes", "Diabetes"]
  Salida:   [[1, 0, 0], [0, 1, 0], [0, 0, 1]]
  ```
- **handle_unknown="ignore"**: Maneja categor√≠as no vistas en entrenamiento

---

#### `ColumnTransformer`
```python
from sklearn.compose import ColumnTransformer

preprocessor = ColumnTransformer(
    transformers=[
        ("num", "passthrough", numeric_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_cols)
    ]
)
```

- **Funci√≥n**: Aplica transformaciones diferentes por tipo de columna
- **"passthrough"**: Deja columnas num√©ricas sin cambios
- **OneHotEncoder**: Transforma solo las categ√≥ricas

---

#### `Pipeline`
```python
from sklearn.pipeline import Pipeline

model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", GradientBoostingRegressor(...))
])
```

- **Funci√≥n**: Encadena preprocesamiento y modelo
- **Ventaja**: Evita data leakage (fuga de informaci√≥n entre train/test)
- **Flujo**: `Datos Brutos ‚Üí Preprocessor ‚Üí Modelo ‚Üí Predicci√≥n`

---

#### `M√©tricas de Evaluaci√≥n`
```python
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error

r2 = r2_score(y_real, y_predicho)
rmse = np.sqrt(mean_squared_error(y_real, y_predicho))
mae = mean_absolute_error(y_real, y_predicho)
```

| M√©trica | F√≥rmula | Interpretaci√≥n |
|---------|---------|----------------|
| **R¬≤** | `1 - (SS_res / SS_tot)` | Proporci√≥n de varianza explicada (0-1) |
| **RMSE** | `‚àö(Œ£(y_real - y_pred)¬≤ / n)` | Error promedio en mg/dL |
| **MAE** | `Œ£\|y_real - y_pred\| / n` | Error absoluto medio en mg/dL |

---

### **Joblib**
```python
import joblib

# Guardar modelo
joblib.dump(model, "modelo.joblib")

# Cargar modelo
modelo_cargado = joblib.load("modelo.joblib")
```

- **Funci√≥n**: Serializa modelos entrenados
- **Ventaja**: Reutilizar sin reentrenamiento

---

## üìä Caracter√≠sticas (Features)

El modelo utiliza **7 caracter√≠sticas** como entrada:

| Feature | Tipo | Descripci√≥n | Rango T√≠pico |
|---------|------|-------------|--------------|
| **Edad_A√±os** | Num√©rica | Edad del paciente | 18-100 a√±os |
| **peso** | Num√©rica | Peso corporal | kg |
| **talla** | Num√©rica | Altura/Talla | cm |
| **imc** | Num√©rica | √çndice de Masa Corporal | 10-50 kg/m¬≤ |
| **tas** | Num√©rica | Tensi√≥n Arterial Sist√≥lica | 80-200 mmHg |
| **tad** | Num√©rica | Tensi√≥n Arterial Diast√≥lica | 40-120 mmHg |
| **Categoria_Glucosa** | Categ√≥rica | Clasificaci√≥n previa de glucosa | Nominal |

### Justificaci√≥n de Features

- **Datos antropom√©tricos** (edad, peso, talla, IMC): Relacionados con metabolismo y resistencia a insulina
- **Presi√≥n arterial** (TAS, TAD): Correlacionada con diabetes tipo 2
- **Categor√≠a de glucosa**: Referencia cl√≠nica previa del paciente

### Variable Objetivo (Target)
- **"Resultado"**: Medici√≥n de glucosa (en ayunas o general) que se transforma en glucosa postprandial

---

## üßÆ Transformaci√≥n de Datos

### Estimaci√≥n de Glucosa Postprandial
```python
Glucosa_Post_Estimada = Resultado + 40  # mg/dL
Glucosa_Post_Estimada = max(Glucosa_Post_Estimada, 70)  # M√≠nimo cl√≠nico
```

**L√≥gica**:
- La glucosa postprandial es t√≠picamente **40 mg/dL mayor** que en ayunas
- Se asegura un **m√≠nimo de 70 mg/dL** (valor cl√≠nicamente significativo)
- Esto simula el aumento esperado despu√©s de la ingesta de alimentos

### Limpieza de Datos
```python
df_limpio = df.dropna(subset=features_seleccionadas + [target]).copy()
```
- Elimina filas con valores faltantes
- `copy()` evita modificaciones en el DataFrame original

---

## üè∑Ô∏è Clasificaci√≥n Cl√≠nica Postprandial

```python
def clasificar_glucosa_post(valor):
    if valor < 140:
        return "Normal"
    elif 140 <= valor <= 199:
        return "Prediabetes"
    else:
        return "Diabetes"
```

### Criterios de Clasificaci√≥n (OMS/ADA) - Postprandial

| Clasificaci√≥n | Rango (mg/dL) | Interpretaci√≥n |
|---------------|---------------|----------------|
| **Normal** | < 140 | Metabolismo de glucosa saludable |
| **Prediabetes** | 140-199 | Riesgo de desarrollar diabetes |
| **Diabetes** | ‚â• 200 | Diabetes mellitus diagnosticada |

**Est√°ndares**:
- Basado en **Prueba de Tolerancia Oral a la Glucosa (PTGO)**
- Criterios de la OMS y Asociaci√≥n Americana de Diabetes (ADA)
- Medici√≥n a los 120 minutos post-comida

---

## üîÑ Estructura Com√∫n del C√≥digo

Todos los 7 modelos siguen esta estructura id√©ntica:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. CARGAR DATOS (CSV)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  2. CREAR CATEGOR√çAS DE GLUCOSA     ‚îÇ
‚îÇ     (Normal/Prediabetes/Diabetes)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  3. ESTIMAR GLUCOSA POSTPRANDIAL    ‚îÇ
‚îÇ     Resultado + 40 mg/dL            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  4. SELECCIONAR FEATURES (7)        ‚îÇ
‚îÇ     y TARGET (Resultado)            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  5. LIMPIAR DATOS                   ‚îÇ
‚îÇ     dropna() en target              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  6. PREPROCESAR                     ‚îÇ
‚îÇ     Num√©ricas: passthrough          ‚îÇ
‚îÇ     Categ√≥ricas: OneHotEncoder      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  7. DIVIDIR DATOS                   ‚îÇ
‚îÇ     70% train / 30% test            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  8. CREAR PIPELINE                  ‚îÇ
‚îÇ     Preprocessor + Modelo           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  9. ENTRENAR MODELO                 ‚îÇ
‚îÇ     model.fit(X_train, y_train)     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  10. EVALUAR                        ‚îÇ
‚îÇ     Calcular R¬≤, RMSE, MAE          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
             ‚îÇ
             ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  11. GUARDAR MODELO                 ‚îÇ
‚îÇ      joblib.dump()                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìà Comparativa de Desempe√±o

Se entrenaron 7 modelos diferentes para predicci√≥n de glucosa postprandial:

| Modelo | R¬≤ Test | RMSE Test | MAE Test | Recomendaci√≥n |
|--------|---------|-----------|----------|--------------|
| **Random Forest** ü•á | 0.8622 | 12.62 mg/dL | 9.69 mg/dL | ‚≠ê MEJOR |
| **Gradient Boosting** ü•à | 0.8240 | 14.27 mg/dL | 10.90 mg/dL | ‚≠ê‚≠ê Buena |
| **Ridge Regression** ü•â | 0.8237 | 14.28 mg/dL | 11.26 mg/dL | ‚≠ê‚≠ê R√°pida |
| Lasso Regression | 0.8237 | 14.28 mg/dL | 11.24 mg/dL | ‚≠ê‚≠ê R√°pida |
| Regresi√≥n Lineal | 0.8233 | 14.29 mg/dL | 11.28 mg/dL | ‚≠ê Baseline |
| Support Vector Machine | 0.8114 | 14.77 mg/dL | 11.55 mg/dL | ‚≠ê Moderada |
| Red Neuronal (MLP) | 0.7956 | 15.37 mg/dL | 11.94 mg/dL | ‚≠ê Menor |

---

## üéØ Modelos Implementados

### 1. Regresi√≥n Lineal
- **Caracter√≠sticas**: Simple, interpretable, baseline
- **Ventaja**: Muy r√°pida
- **Desventaja**: No captura no-linealidades
- **Caso de uso**: Comparaci√≥n base

### 2. Ridge Regression (L2 Regularization)
- **Caracter√≠sticas**: Regresi√≥n lineal con penalizaci√≥n
- **Ventaja**: Evita sobreajuste, muy r√°pida
- **Desventaja**: Mantiene todas las variables
- **Caso de uso**: Cuando se necesita estabilidad y velocidad

### 3. Lasso Regression (L1 Regularization)
- **Caracter√≠sticas**: Regresi√≥n lineal con sparsity
- **Ventaja**: Selecciona autom√°ticamente features importantes
- **Desventaja**: Puede eliminar variables √∫tiles
- **Caso de uso**: Selecci√≥n de variables

### 4. Random Forest ‚≠ê RECOMENDADO
- **Caracter√≠sticas**: Ensamble de √°rboles paralelos
- **Ventaja**: Mejor precisi√≥n (R¬≤=0.8622), robusto
- **Desventaja**: Requiere m√°s memoria
- **Caso de uso**: M√°xima precisi√≥n en producci√≥n

### 5. Gradient Boosting
- **Caracter√≠sticas**: Ensamble secuencial de √°rboles d√©biles
- **Ventaja**: Muy buena precisi√≥n (R¬≤=0.8240), captura no-linealidades
- **Desventaja**: Lento en entrenamiento
- **Caso de uso**: Datos complejos

### 6. Support Vector Machine (SVM)
- **Caracter√≠sticas**: Busca hiperplano √≥ptimo
- **Ventaja**: Bueno en espacios de alta dimensi√≥n
- **Desventaja**: R¬≤ menor (0.8114)
- **Caso de uso**: Cuando hay muchas features

### 7. Red Neuronal (MLP)
- **Caracter√≠sticas**: Redes con capas densas
- **Ventaja**: Flexible, aprende patrones complejos
- **Desventaja**: Desempe√±o menor (R¬≤=0.7956), requiere m√°s datos
- **Caso de uso**: Datasets muy grandes

---

## üî® Ejemplo de C√≥digo: Gradient Boosting

```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
import joblib

# 1. Cargar datos
df = pd.read_csv("Glucosa_Unique_Completo.csv")

# 2. Crear categor√≠as
def clasificar_glucosa(valor):
    if valor <= 100:
        return "Normal"
    elif valor <= 125:
        return "Prediabetes"
    else:
        return "Diabetes"

df["Categoria_Glucosa"] = df["Resultado"].apply(clasificar_glucosa)

# 3. Seleccionar features
features_seleccionadas = [
    "Edad_A√±os", "peso", "talla", "imc", "tas", "tad", "Categoria_Glucosa"
]
target = "Resultado"

df_limpio = df.dropna(subset=features_seleccionadas + [target]).copy()
X = df_limpio[features_seleccionadas]
y = df_limpio[target]

# 4. Preprocesador
numeric_cols = X.select_dtypes(include=["int64", "float64"]).columns
categorical_cols = X.select_dtypes(exclude=["int64", "float64"]).columns

preprocessor = ColumnTransformer(
    transformers=[
        ("num", "passthrough", numeric_cols),
        ("cat", OneHotEncoder(handle_unknown="ignore"), categorical_cols)
    ]
)

# 5. Pipeline con Gradient Boosting
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("regressor", GradientBoostingRegressor(
        n_estimators=200,
        learning_rate=0.1,
        max_depth=5,
        random_state=42
    ))
])

# 6. Dividir datos
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42
)

# 7. Entrenar
model.fit(X_train, y_train)

# 8. Evaluar
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

r2_train = r2_score(y_train, y_pred_train)
rmse_train = (mean_squared_error(y_train, y_pred_train))**0.5
mae_train = mean_absolute_error(y_train, y_pred_train)

r2_test = r2_score(y_test, y_pred_test)
rmse_test = (mean_squared_error(y_test, y_pred_test))**0.5
mae_test = mean_absolute_error(y_test, y_pred_test)

print("="*50)
print("EVALUACI√ìN DEL MODELO GRADIENT BOOSTING")
print("="*50)
print(f"[ENTRENAMIENTO] R¬≤={r2_train:.3f} | RMSE={rmse_train:.2f} mg/dL | MAE={mae_train:.2f} mg/dL")
print(f"[PRUEBA       ] R¬≤={r2_test:.3f} | RMSE={rmse_test:.2f} mg/dL | MAE={mae_test:.2f} mg/dL")
print("="*50)

# 9. Guardar
joblib.dump(model, "modelo_gradient_boosting.joblib")
print(f"‚úÖ Modelo guardado")
```

---

## üíæ C√≥mo Usar un Modelo Entrenado

```python
import joblib
import pandas as pd

# Cargar modelo
modelo = joblib.load("modelo_gradient_boosting.joblib")

# Preparar datos nuevos
X_nuevo = pd.DataFrame({
    "Edad_A√±os": [45],
    "peso": [75],
    "talla": [170],
    "imc": [26],
    "tas": [120],
    "tad": [80],
    "Categoria_Glucosa": ["Normal"]
})

# Predecir glucosa postprandial
prediccion = modelo.predict(X_nuevo)
print(f"Glucosa Postprandial Estimada: {prediccion[0]:.2f} mg/dL")

# Clasificar resultado
def clasificar(valor):
    if valor < 140:
        return "Normal"
    elif 140 <= valor <= 199:
        return "Prediabetes"
    else:
        return "Diabetes"

clasificacion = clasificar(prediccion[0])
print(f"Clasificaci√≥n: {clasificacion}")
```

---

## üìä Interpretaci√≥n de M√©tricas

### R¬≤ (Coeficiente de Determinaci√≥n)
- **Rango**: 0 a 1 (m√°s alto es mejor)
- **Interpretaci√≥n**: Proporci√≥n de varianza explicada
- **Ejemplo**: R¬≤=0.86 = El modelo explica el 86% de la variabilidad

### RMSE (Root Mean Squared Error)
- **Unidad**: mg/dL
- **Interpretaci√≥n**: Error promedio esperado
- **Ejemplo**: RMSE=12.62 mg/dL significa error promedio de ¬±12.62 mg/dL

### MAE (Mean Absolute Error)
- **Unidad**: mg/dL
- **Interpretaci√≥n**: Error absoluto promedio
- **Ejemplo**: MAE=9.69 mg/dL significa desviaci√≥n promedio de 9.69 mg/dL

---

## üè• Interpretaci√≥n Cl√≠nica de Errores

**Error de ¬±12-15 mg/dL (RMSE de Random Forest)**:
- ‚úÖ Aceptable para screening inicial
- ‚úÖ Requiere confirmaci√≥n con prueba de laboratorio
- ‚úÖ √ötil para clasificaci√≥n (Normal/Prediabetes/Diabetes)

**Por qu√© es importante**:
- Glucosa Normal: < 140 mg/dL
- Prediabetes: 140-199 mg/dL
- Diabetes: ‚â• 200 mg/dL
- **Error de ¬±12 mg/dL puede cambiar clasificaci√≥n en fronteras**

**Recomendaci√≥n cl√≠nica**:
- Usar modelo para **screening inicial**
- Confirmar con **prueba de laboratorio**
- **No reemplaza diagn√≥stico m√©dico profesional**

---

## üìÅ Estructura de Archivos

```
proyecto-glucosa-postprandial/
‚îÇ
‚îú‚îÄ‚îÄ README.md                                    # Este archivo
‚îú‚îÄ‚îÄ Glucosa_Unique_Completo.csv                  # Dataset
‚îÇ
‚îú‚îÄ‚îÄ modelos/
‚îÇ   ‚îú‚îÄ‚îÄ train_linear_regression.py
‚îÇ   ‚îú‚îÄ‚îÄ train_ridge_regression.py
‚îÇ   ‚îú‚îÄ‚îÄ train_lasso_regression.py
‚îÇ   ‚îú‚îÄ‚îÄ train_random_forest.py
‚îÇ   ‚îú‚îÄ‚îÄ train_gradient_boosting.py               # Ejemplo del c√≥digo
‚îÇ   ‚îú‚îÄ‚îÄ train_svm.py
‚îÇ   ‚îî‚îÄ‚îÄ train_mlp.py
‚îÇ
‚îî‚îÄ‚îÄ modelos_entrenados/
    ‚îú‚îÄ‚îÄ modelo_linear_regression.joblib
    ‚îú‚îÄ‚îÄ modelo_ridge_regression.joblib
    ‚îú‚îÄ‚îÄ modelo_lasso_regression.joblib
    ‚îú‚îÄ‚îÄ modelo_random_forest.joblib
    ‚îú‚îÄ‚îÄ modelo_gradient_boosting.joblib
    ‚îú‚îÄ‚îÄ modelo_svm.joblib
    ‚îî‚îÄ‚îÄ modelo_mlp.joblib
```

---

## ‚úÖ Ventajas de Esta Estructura

- ‚úÖ **Modular**: F√°cil agregar nuevos modelos
- ‚úÖ **Reproducible**: random_state garantiza resultados id√©nticos
- ‚úÖ **Escalable**: Preprocesamiento automatizado
- ‚úÖ **Reutilizable**: Pipeline encapsulado
- ‚úÖ **Comparable**: Todos los modelos con misma metodolog√≠a
- ‚úÖ **Cl√≠nico**: Clasificaci√≥n autom√°tica seg√∫n OMS/ADA

---

## ‚ö†Ô∏è Limitaciones

- ‚ö†Ô∏è Requiere datos de calidad bien estructurados
- ‚ö†Ô∏è Error de ¬±12-15 mg/dL requiere confirmaci√≥n m√©dica
- ‚ö†Ô∏è No sustituye diagn√≥stico profesional
- ‚ö†Ô∏è Modelos espec√≠ficos para predicci√≥n de glucosa postprandial

---

## üöÄ Mejoras Futuras

1. Validaci√≥n cruzada K-Fold para mayor robustez
2. Hiperpar√°metro tuning autom√°tico (Grid Search)
3. Feature importance analysis
4. Comparativa visual con gr√°ficos
5. API REST para despliegue en servidor
6. Dashboard interactivo (Streamlit/Dash)

---

## üìñ Referencias Cl√≠nicas

- OMS (2006): Definici√≥n y diagn√≥stico de diabetes mellitus
- ADA Standards of Care: Criterios de clasificaci√≥n de glucosa postprandial
- PTGO (Prueba de Tolerancia Oral a la Glucosa): Medici√≥n a 120 minutos
- Friedman (2001): Gradient Boosting Machines
- Chen & Guestrin (2016): XGBoost - Scalable Tree Boosting

---

## üë§ Autor

[Tu nombre/equipo]

## üìù Licencia

[Especifica la licencia: MIT, Apache 2.0, etc.]

---

## üìß Contacto

Para preguntas o sugerencias: [tu email]

---

**√öltima actualizaci√≥n**: Octubre 2025
**Versi√≥n**: 1.0
